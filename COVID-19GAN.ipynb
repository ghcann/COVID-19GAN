{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"COVID-19GAN.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMchjVWD0+xs7OTpnIsQXnF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"VU93gNAdqTEW","colab_type":"code","colab":{}},"source":["# COVID-19GAN\n","# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n","# This work is made available under the Nvidia Source Code License-NC.\n","# To view a copy of this license, visit\n","# https://nvlabs.github.io/stylegan2/license.html"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"B5PYGitSoECH","colab_type":"code","outputId":"9d5d527c-e72b-400c-9615-0e14ded9c228","executionInfo":{"status":"ok","timestamp":1585828110522,"user_tz":-60,"elapsed":2621,"user":{"displayName":"George Cann","photoUrl":"","userId":"18306619050321749166"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"k9VJWZXOs2Uk","colab_type":"code","outputId":"e694b6f7-1e0b-4fe1-b7c9-895fd81ed6c3","executionInfo":{"status":"ok","timestamp":1585828110524,"user_tz":-60,"elapsed":2604,"user":{"displayName":"George Cann","photoUrl":"","userId":"18306619050321749166"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["cd '/content/drive/My Drive/StyleGan2/stylegan2-master/'"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/StyleGan2/stylegan2-master\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YxDaoapOo91F","colab_type":"code","outputId":"c094ee31-4c10-4226-9c06-4ead99cfb766","executionInfo":{"status":"ok","timestamp":1585828120829,"user_tz":-60,"elapsed":12889,"user":{"displayName":"George Cann","photoUrl":"","userId":"18306619050321749166"}},"colab":{"base_uri":"https://localhost:8080/","height":849}},"source":["### Install tensorflow with pip \n","!pip install tensorflow==1.4.0\n","\n","### Install tensorflow with pip \n","!pip install tensorflow-gpu"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow==1.4.0 in /usr/local/lib/python3.6/dist-packages (1.4.0)\n","Requirement already satisfied: numpy>=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.18.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.12.0)\n","Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (1.1.10)\n","Requirement already satisfied: protobuf>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (3.10.0)\n","Requirement already satisfied: tensorflow-tensorboard<0.5.0,>=0.4.0rc1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (0.4.0)\n","Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.4.0) (0.34.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.3.0->tensorflow==1.4.0) (46.0.0)\n","Requirement already satisfied: html5lib==0.9999999 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (0.9999999)\n","Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (1.0.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (3.2.1)\n","Requirement already satisfied: bleach==1.5.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-tensorboard<0.5.0,>=0.4.0rc1->tensorflow==1.4.0) (1.5.0)\n","Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.6/dist-packages (2.1.0)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.18.2)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.9.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.10.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.0)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.27.2)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.1.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.0.8)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (3.2.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.34.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.8.1)\n","Requirement already satisfied: tensorflow-estimator<2.2.0,>=2.1.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.1.0)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.1)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.12.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (1.4.1)\n","Requirement already satisfied: tensorboard<2.2.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (2.1.1)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu) (0.2.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->tensorflow-gpu) (46.0.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu) (2.10.0)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.21.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.2.1)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.7.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.0.0)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2.8)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.0.4)\n","Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (2019.11.28)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (1.3.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.1)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.2.8)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (4.0)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (3.1.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.2.0,>=2.1.0->tensorflow-gpu) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"zpHMaNTsrUtk","outputId":"0dd2cbb1-8b2d-47f8-8a36-2fcb54636170","executionInfo":{"status":"ok","timestamp":1585828125543,"user_tz":-60,"elapsed":17586,"user":{"displayName":"George Cann","photoUrl":"","userId":"18306619050321749166"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["### Run the following which creates a tfrecord version from  which contains the 256x256 pixel greyscale training images\n","# python dataset_tool.py create_from_images datasets/02_02_varepsilon_refined_tfrecord datasets/02_02_varepsilon_refined\n","# As COVID-19GAN runs in colab the training and tfrecord datasets should be passed into dataset_tool.py in an alternative \n","# manner datasets/02_02_varepsilon_refined_tfrecord datasets/02_02_varepsilon_refined\n","\n","\"\"\"Tool for creating multi-resolution TFRecords datasets.\"\"\"\n","\n","# To use TF 1.x instead, restart your runtime (Ctrl+M .) and run \"%tensorflow_version 1.x\" before you run \"import tensorflow\".\n","%tensorflow_version 1.x \n","\n","# pylint: disable=too-many-lines\n","import os\n","import sys\n","import glob\n","import argparse\n","import threading\n","import six.moves.queue as Queue # pylint: disable=import-error\n","import traceback\n","import numpy as np\n","import tensorflow as tf\n","import PIL.Image\n","import dnnlib.tflib as tflib\n","\n","from training import dataset\n","\n","# Default arguments\n","CREATE_FROM_IMAGES = True\n","TFRECORD_DIR = '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord'\n","IMAGE_DIR = '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined'\n","\n","#----------------------------------------------------------------------------\n","\n","def error(msg):\n","    print('Error: ' + msg)\n","    exit(1)\n","\n","#----------------------------------------------------------------------------\n","\n","class TFRecordExporter:\n","    def __init__(self, tfrecord_dir, expected_images, print_progress=True, progress_interval=10):\n","        self.tfrecord_dir       = tfrecord_dir\n","        self.tfr_prefix         = os.path.join(self.tfrecord_dir, os.path.basename(self.tfrecord_dir))\n","        self.expected_images    = expected_images\n","        self.cur_images         = 0\n","        self.shape              = None\n","        self.resolution_log2    = None\n","        self.tfr_writers        = []\n","        self.print_progress     = print_progress\n","        self.progress_interval  = progress_interval\n","\n","        if self.print_progress:\n","            print('Creating dataset \"%s\"' % tfrecord_dir)\n","        if not os.path.isdir(self.tfrecord_dir):\n","            os.makedirs(self.tfrecord_dir)\n","        assert os.path.isdir(self.tfrecord_dir)\n","\n","    def close(self):\n","        if self.print_progress:\n","            print('%-40s\\r' % 'Flushing data...', end='', flush=True)\n","        for tfr_writer in self.tfr_writers:\n","            tfr_writer.close()\n","        self.tfr_writers = []\n","        if self.print_progress:\n","            print('%-40s\\r' % '', end='', flush=True)\n","            print('Added %d images.' % self.cur_images)\n","\n","    def choose_shuffled_order(self): # Note: Images and labels must be added in shuffled order.\n","        order = np.arange(self.expected_images)\n","        np.random.RandomState(123).shuffle(order)\n","        return order\n","\n","    def add_image(self, img):\n","        if self.print_progress and self.cur_images % self.progress_interval == 0:\n","            print('%d / %d\\r' % (self.cur_images, self.expected_images), end='', flush=True)\n","        if self.shape is None:\n","            self.shape = img.shape\n","            self.resolution_log2 = int(np.log2(self.shape[1]))\n","            assert self.shape[0] in [1, 3]\n","            assert self.shape[1] == self.shape[2]\n","            assert self.shape[1] == 2**self.resolution_log2\n","            tfr_opt = tf.python_io.TFRecordOptions(tf.python_io.TFRecordCompressionType.NONE)\n","            for lod in range(self.resolution_log2 - 1):\n","                tfr_file = self.tfr_prefix + '-r%02d.tfrecords' % (self.resolution_log2 - lod)\n","                self.tfr_writers.append(tf.python_io.TFRecordWriter(tfr_file, tfr_opt))\n","        assert img.shape == self.shape\n","        for lod, tfr_writer in enumerate(self.tfr_writers):\n","            if lod:\n","                img = img.astype(np.float32)\n","                img = (img[:, 0::2, 0::2] + img[:, 0::2, 1::2] + img[:, 1::2, 0::2] + img[:, 1::2, 1::2]) * 0.25\n","            quant = np.rint(img).clip(0, 255).astype(np.uint8)\n","            ex = tf.train.Example(features=tf.train.Features(feature={\n","                'shape': tf.train.Feature(int64_list=tf.train.Int64List(value=quant.shape)),\n","                'data': tf.train.Feature(bytes_list=tf.train.BytesList(value=[quant.tostring()]))}))\n","            tfr_writer.write(ex.SerializeToString())\n","        self.cur_images += 1\n","\n","    def add_labels(self, labels):\n","        if self.print_progress:\n","            print('%-40s\\r' % 'Saving labels...', end='', flush=True)\n","        assert labels.shape[0] == self.cur_images\n","        with open(self.tfr_prefix + '-rxx.labels', 'wb') as f:\n","            np.save(f, labels.astype(np.float32))\n","\n","    def __enter__(self):\n","        return self\n","\n","    def __exit__(self, *args):\n","        self.close()\n","\n","#----------------------------------------------------------------------------\n","\n","class ExceptionInfo(object):\n","    def __init__(self):\n","        self.value = sys.exc_info()[1]\n","        self.traceback = traceback.format_exc()\n","\n","#----------------------------------------------------------------------------\n","\n","class WorkerThread(threading.Thread):\n","    def __init__(self, task_queue):\n","        threading.Thread.__init__(self)\n","        self.task_queue = task_queue\n","\n","    def run(self):\n","        while True:\n","            func, args, result_queue = self.task_queue.get()\n","            if func is None:\n","                break\n","            try:\n","                result = func(*args)\n","            except:\n","                result = ExceptionInfo()\n","            result_queue.put((result, args))\n","\n","#----------------------------------------------------------------------------\n","\n","class ThreadPool(object):\n","    def __init__(self, num_threads):\n","        assert num_threads >= 1\n","        self.task_queue = Queue.Queue()\n","        self.result_queues = dict()\n","        self.num_threads = num_threads\n","        for _idx in range(self.num_threads):\n","            thread = WorkerThread(self.task_queue)\n","            thread.daemon = True\n","            thread.start()\n","\n","    def add_task(self, func, args=()):\n","        assert hasattr(func, '__call__') # must be a function\n","        if func not in self.result_queues:\n","            self.result_queues[func] = Queue.Queue()\n","        self.task_queue.put((func, args, self.result_queues[func]))\n","\n","    def get_result(self, func): # returns (result, args)\n","        result, args = self.result_queues[func].get()\n","        if isinstance(result, ExceptionInfo):\n","            print('\\n\\nWorker thread caught an exception:\\n' + result.traceback)\n","            raise result.value\n","        return result, args\n","\n","    def finish(self):\n","        for _idx in range(self.num_threads):\n","            self.task_queue.put((None, (), None))\n","\n","    def __enter__(self): # for 'with' statement\n","        return self\n","\n","    def __exit__(self, *excinfo):\n","        self.finish()\n","\n","    def process_items_concurrently(self, item_iterator, process_func=lambda x: x, pre_func=lambda x: x, post_func=lambda x: x, max_items_in_flight=None):\n","        if max_items_in_flight is None: max_items_in_flight = self.num_threads * 4\n","        assert max_items_in_flight >= 1\n","        results = []\n","        retire_idx = [0]\n","\n","        def task_func(prepared, _idx):\n","            return process_func(prepared)\n","\n","        def retire_result():\n","            processed, (_prepared, idx) = self.get_result(task_func)\n","            results[idx] = processed\n","            while retire_idx[0] < len(results) and results[retire_idx[0]] is not None:\n","                yield post_func(results[retire_idx[0]])\n","                results[retire_idx[0]] = None\n","                retire_idx[0] += 1\n","\n","        for idx, item in enumerate(item_iterator):\n","            prepared = pre_func(item)\n","            results.append(None)\n","            self.add_task(func=task_func, args=(prepared, idx))\n","            while retire_idx[0] < idx - max_items_in_flight + 2:\n","                for res in retire_result(): yield res\n","        while retire_idx[0] < len(results):\n","            for res in retire_result(): yield res\n","\n","#----------------------------------------------------------------------------\n","\n","def display(tfrecord_dir):\n","    print('Loading dataset \"%s\"' % tfrecord_dir)\n","    tflib.init_tf({'gpu_options.allow_growth': True})\n","    dset = dataset.TFRecordDataset(tfrecord_dir, max_label_size='full', repeat=False, shuffle_mb=0)\n","    tflib.init_uninitialized_vars()\n","    import cv2  # pip install opencv-python\n","\n","    idx = 0\n","    while True:\n","        try:\n","            images, labels = dset.get_minibatch_np(1)\n","        except tf.errors.OutOfRangeError:\n","            break\n","        if idx == 0:\n","            print('Displaying images')\n","            cv2.namedWindow('dataset_tool')\n","            print('Press SPACE or ENTER to advance, ESC to exit')\n","        print('\\nidx = %-8d\\nlabel = %s' % (idx, labels[0].tolist()))\n","        cv2.imshow('dataset_tool', images[0].transpose(1, 2, 0)[:, :, ::-1]) # CHW => HWC, RGB => BGR\n","        idx += 1\n","        if cv2.waitKey() == 27:\n","            break\n","    print('\\nDisplayed %d images.' % idx)\n","\n","#----------------------------------------------------------------------------\n","\n","def extract(tfrecord_dir, output_dir):\n","    print('Loading dataset \"%s\"' % tfrecord_dir)\n","    tflib.init_tf({'gpu_options.allow_growth': True})\n","    dset = dataset.TFRecordDataset(tfrecord_dir, max_label_size=0, repeat=False, shuffle_mb=0)\n","    tflib.init_uninitialized_vars()\n","\n","    print('Extracting images to \"%s\"' % output_dir)\n","    if not os.path.isdir(output_dir):\n","        os.makedirs(output_dir)\n","    idx = 0\n","    while True:\n","        if idx % 10 == 0:\n","            print('%d\\r' % idx, end='', flush=True)\n","        try:\n","            images, _labels = dset.get_minibatch_np(1)\n","        except tf.errors.OutOfRangeError:\n","            break\n","        if images.shape[1] == 1:\n","            img = PIL.Image.fromarray(images[0][0], 'L')\n","        else:\n","            img = PIL.Image.fromarray(images[0].transpose(1, 2, 0), 'RGB')\n","        img.save(os.path.join(output_dir, 'img%08d.png' % idx))\n","        idx += 1\n","    print('Extracted %d images.' % idx)\n","\n","#----------------------------------------------------------------------------\n","\n","def compare(tfrecord_dir_a, tfrecord_dir_b, ignore_labels):\n","    max_label_size = 0 if ignore_labels else 'full'\n","    print('Loading dataset \"%s\"' % tfrecord_dir_a)\n","    tflib.init_tf({'gpu_options.allow_growth': True})\n","    dset_a = dataset.TFRecordDataset(tfrecord_dir_a, max_label_size=max_label_size, repeat=False, shuffle_mb=0)\n","    print('Loading dataset \"%s\"' % tfrecord_dir_b)\n","    dset_b = dataset.TFRecordDataset(tfrecord_dir_b, max_label_size=max_label_size, repeat=False, shuffle_mb=0)\n","    tflib.init_uninitialized_vars()\n","\n","    print('Comparing datasets')\n","    idx = 0\n","    identical_images = 0\n","    identical_labels = 0\n","    while True:\n","        if idx % 100 == 0:\n","            print('%d\\r' % idx, end='', flush=True)\n","        try:\n","            images_a, labels_a = dset_a.get_minibatch_np(1)\n","        except tf.errors.OutOfRangeError:\n","            images_a, labels_a = None, None\n","        try:\n","            images_b, labels_b = dset_b.get_minibatch_np(1)\n","        except tf.errors.OutOfRangeError:\n","            images_b, labels_b = None, None\n","        if images_a is None or images_b is None:\n","            if images_a is not None or images_b is not None:\n","                print('Datasets contain different number of images')\n","            break\n","        if images_a.shape == images_b.shape and np.all(images_a == images_b):\n","            identical_images += 1\n","        else:\n","            print('Image %d is different' % idx)\n","        if labels_a.shape == labels_b.shape and np.all(labels_a == labels_b):\n","            identical_labels += 1\n","        else:\n","            print('Label %d is different' % idx)\n","        idx += 1\n","    print('Identical images: %d / %d' % (identical_images, idx))\n","    if not ignore_labels:\n","        print('Identical labels: %d / %d' % (identical_labels, idx))\n","\n","#----------------------------------------------------------------------------\n","\n","def create_mnist(tfrecord_dir, mnist_dir):\n","    print('Loading MNIST from \"%s\"' % mnist_dir)\n","    import gzip\n","    with gzip.open(os.path.join(mnist_dir, 'train-images-idx3-ubyte.gz'), 'rb') as file:\n","        images = np.frombuffer(file.read(), np.uint8, offset=16)\n","    with gzip.open(os.path.join(mnist_dir, 'train-labels-idx1-ubyte.gz'), 'rb') as file:\n","        labels = np.frombuffer(file.read(), np.uint8, offset=8)\n","    images = images.reshape(-1, 1, 28, 28)\n","    images = np.pad(images, [(0,0), (0,0), (2,2), (2,2)], 'constant', constant_values=0)\n","    assert images.shape == (60000, 1, 32, 32) and images.dtype == np.uint8\n","    assert labels.shape == (60000,) and labels.dtype == np.uint8\n","    assert np.min(images) == 0 and np.max(images) == 255\n","    assert np.min(labels) == 0 and np.max(labels) == 9\n","    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n","    onehot[np.arange(labels.size), labels] = 1.0\n","\n","    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n","        order = tfr.choose_shuffled_order()\n","        for idx in range(order.size):\n","            tfr.add_image(images[order[idx]])\n","        tfr.add_labels(onehot[order])\n","\n","#----------------------------------------------------------------------------\n","\n","def create_mnistrgb(tfrecord_dir, mnist_dir, num_images=1000000, random_seed=123):\n","    print('Loading MNIST from \"%s\"' % mnist_dir)\n","    import gzip\n","    with gzip.open(os.path.join(mnist_dir, 'train-images-idx3-ubyte.gz'), 'rb') as file:\n","        images = np.frombuffer(file.read(), np.uint8, offset=16)\n","    images = images.reshape(-1, 28, 28)\n","    images = np.pad(images, [(0,0), (2,2), (2,2)], 'constant', constant_values=0)\n","    assert images.shape == (60000, 32, 32) and images.dtype == np.uint8\n","    assert np.min(images) == 0 and np.max(images) == 255\n","\n","    with TFRecordExporter(tfrecord_dir, num_images) as tfr:\n","        rnd = np.random.RandomState(random_seed)\n","        for _idx in range(num_images):\n","            tfr.add_image(images[rnd.randint(images.shape[0], size=3)])\n","\n","#----------------------------------------------------------------------------\n","\n","def create_cifar10(tfrecord_dir, cifar10_dir):\n","    print('Loading CIFAR-10 from \"%s\"' % cifar10_dir)\n","    import pickle\n","    images = []\n","    labels = []\n","    for batch in range(1, 6):\n","        with open(os.path.join(cifar10_dir, 'data_batch_%d' % batch), 'rb') as file:\n","            data = pickle.load(file, encoding='latin1')\n","        images.append(data['data'].reshape(-1, 3, 32, 32))\n","        labels.append(data['labels'])\n","    images = np.concatenate(images)\n","    labels = np.concatenate(labels)\n","    assert images.shape == (50000, 3, 32, 32) and images.dtype == np.uint8\n","    assert labels.shape == (50000,) and labels.dtype == np.int32\n","    assert np.min(images) == 0 and np.max(images) == 255\n","    assert np.min(labels) == 0 and np.max(labels) == 9\n","    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n","    onehot[np.arange(labels.size), labels] = 1.0\n","\n","    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n","        order = tfr.choose_shuffled_order()\n","        for idx in range(order.size):\n","            tfr.add_image(images[order[idx]])\n","        tfr.add_labels(onehot[order])\n","\n","#----------------------------------------------------------------------------\n","\n","def create_cifar100(tfrecord_dir, cifar100_dir):\n","    print('Loading CIFAR-100 from \"%s\"' % cifar100_dir)\n","    import pickle\n","    with open(os.path.join(cifar100_dir, 'train'), 'rb') as file:\n","        data = pickle.load(file, encoding='latin1')\n","    images = data['data'].reshape(-1, 3, 32, 32)\n","    labels = np.array(data['fine_labels'])\n","    assert images.shape == (50000, 3, 32, 32) and images.dtype == np.uint8\n","    assert labels.shape == (50000,) and labels.dtype == np.int32\n","    assert np.min(images) == 0 and np.max(images) == 255\n","    assert np.min(labels) == 0 and np.max(labels) == 99\n","    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n","    onehot[np.arange(labels.size), labels] = 1.0\n","\n","    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n","        order = tfr.choose_shuffled_order()\n","        for idx in range(order.size):\n","            tfr.add_image(images[order[idx]])\n","        tfr.add_labels(onehot[order])\n","\n","#----------------------------------------------------------------------------\n","\n","def create_svhn(tfrecord_dir, svhn_dir):\n","    print('Loading SVHN from \"%s\"' % svhn_dir)\n","    import pickle\n","    images = []\n","    labels = []\n","    for batch in range(1, 4):\n","        with open(os.path.join(svhn_dir, 'train_%d.pkl' % batch), 'rb') as file:\n","            data = pickle.load(file, encoding='latin1')\n","        images.append(data[0])\n","        labels.append(data[1])\n","    images = np.concatenate(images)\n","    labels = np.concatenate(labels)\n","    assert images.shape == (73257, 3, 32, 32) and images.dtype == np.uint8\n","    assert labels.shape == (73257,) and labels.dtype == np.uint8\n","    assert np.min(images) == 0 and np.max(images) == 255\n","    assert np.min(labels) == 0 and np.max(labels) == 9\n","    onehot = np.zeros((labels.size, np.max(labels) + 1), dtype=np.float32)\n","    onehot[np.arange(labels.size), labels] = 1.0\n","\n","    with TFRecordExporter(tfrecord_dir, images.shape[0]) as tfr:\n","        order = tfr.choose_shuffled_order()\n","        for idx in range(order.size):\n","            tfr.add_image(images[order[idx]])\n","        tfr.add_labels(onehot[order])\n","\n","#----------------------------------------------------------------------------\n","\n","def create_lsun(tfrecord_dir, lmdb_dir, resolution=256, max_images=None):\n","    print('Loading LSUN dataset from \"%s\"' % lmdb_dir)\n","    import lmdb # pip install lmdb # pylint: disable=import-error\n","    import cv2 # pip install opencv-python\n","    import io\n","    with lmdb.open(lmdb_dir, readonly=True).begin(write=False) as txn:\n","        total_images = txn.stat()['entries'] # pylint: disable=no-value-for-parameter\n","        if max_images is None:\n","            max_images = total_images\n","        with TFRecordExporter(tfrecord_dir, max_images) as tfr:\n","            for _idx, (_key, value) in enumerate(txn.cursor()):\n","                try:\n","                    try:\n","                        img = cv2.imdecode(np.fromstring(value, dtype=np.uint8), 1)\n","                        if img is None:\n","                            raise IOError('cv2.imdecode failed')\n","                        img = img[:, :, ::-1] # BGR => RGB\n","                    except IOError:\n","                        img = np.asarray(PIL.Image.open(io.BytesIO(value)))\n","                    crop = np.min(img.shape[:2])\n","                    img = img[(img.shape[0] - crop) // 2 : (img.shape[0] + crop) // 2, (img.shape[1] - crop) // 2 : (img.shape[1] + crop) // 2]\n","                    img = PIL.Image.fromarray(img, 'RGB')\n","                    img = img.resize((resolution, resolution), PIL.Image.ANTIALIAS)\n","                    img = np.asarray(img)\n","                    img = img.transpose([2, 0, 1]) # HWC => CHW\n","                    tfr.add_image(img)\n","                except:\n","                    print(sys.exc_info()[1])\n","                if tfr.cur_images == max_images:\n","                    break\n","\n","#----------------------------------------------------------------------------\n","\n","def create_lsun_wide(tfrecord_dir, lmdb_dir, width=512, height=384, max_images=None):\n","    assert width == 2 ** int(np.round(np.log2(width)))\n","    assert height <= width\n","    print('Loading LSUN dataset from \"%s\"' % lmdb_dir)\n","    import lmdb # pip install lmdb # pylint: disable=import-error\n","    import cv2 # pip install opencv-python\n","    import io\n","    with lmdb.open(lmdb_dir, readonly=True).begin(write=False) as txn:\n","        total_images = txn.stat()['entries'] # pylint: disable=no-value-for-parameter\n","        if max_images is None:\n","            max_images = total_images\n","        with TFRecordExporter(tfrecord_dir, max_images, print_progress=False) as tfr:\n","            for idx, (_key, value) in enumerate(txn.cursor()):\n","                try:\n","                    try:\n","                        img = cv2.imdecode(np.fromstring(value, dtype=np.uint8), 1)\n","                        if img is None:\n","                            raise IOError('cv2.imdecode failed')\n","                        img = img[:, :, ::-1] # BGR => RGB\n","                    except IOError:\n","                        img = np.asarray(PIL.Image.open(io.BytesIO(value)))\n","\n","                    ch = int(np.round(width * img.shape[0] / img.shape[1]))\n","                    if img.shape[1] < width or ch < height:\n","                        continue\n","\n","                    img = img[(img.shape[0] - ch) // 2 : (img.shape[0] + ch) // 2]\n","                    img = PIL.Image.fromarray(img, 'RGB')\n","                    img = img.resize((width, height), PIL.Image.ANTIALIAS)\n","                    img = np.asarray(img)\n","                    img = img.transpose([2, 0, 1]) # HWC => CHW\n","\n","                    canvas = np.zeros([3, width, width], dtype=np.uint8)\n","                    canvas[:, (width - height) // 2 : (width + height) // 2] = img\n","                    tfr.add_image(canvas)\n","                    print('\\r%d / %d => %d ' % (idx + 1, total_images, tfr.cur_images), end='')\n","\n","                except:\n","                    print(sys.exc_info()[1])\n","                if tfr.cur_images == max_images:\n","                    break\n","    print()\n","\n","#----------------------------------------------------------------------------\n","\n","def create_celeba(tfrecord_dir, celeba_dir, cx=89, cy=121):\n","    print('Loading CelebA from \"%s\"' % celeba_dir)\n","    glob_pattern = os.path.join(celeba_dir, 'img_align_celeba_png', '*.png')\n","    image_filenames = sorted(glob.glob(glob_pattern))\n","    expected_images = 202599\n","    if len(image_filenames) != expected_images:\n","        error('Expected to find %d images' % expected_images)\n","\n","    with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n","        order = tfr.choose_shuffled_order()\n","        for idx in range(order.size):\n","            img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n","            assert img.shape == (218, 178, 3)\n","            img = img[cy - 64 : cy + 64, cx - 64 : cx + 64]\n","            img = img.transpose(2, 0, 1) # HWC => CHW\n","            tfr.add_image(img)\n","\n","#----------------------------------------------------------------------------\n","\n","def create_from_images(tfrecord_dir, image_dir, shuffle):\n","    print('Loading images from \"%s\"' % image_dir)\n","    image_filenames = sorted(glob.glob(os.path.join(image_dir, '*')))\n","    if len(image_filenames) == 0:\n","        error('No input images found')\n","\n","    img = np.asarray(PIL.Image.open(image_filenames[0]))\n","    resolution = img.shape[0]\n","    channels = img.shape[2] if img.ndim == 3 else 1\n","    if img.shape[1] != resolution:\n","        error('Input images must have the same width and height')\n","    if resolution != 2 ** int(np.floor(np.log2(resolution))):\n","        error('Input image resolution must be a power-of-two')\n","    if channels not in [1, 3]:\n","        error('Input images must be stored as RGB or grayscale')\n","\n","    with TFRecordExporter(tfrecord_dir, len(image_filenames)) as tfr:\n","        order = tfr.choose_shuffled_order() if shuffle else np.arange(len(image_filenames))\n","        for idx in range(order.size):\n","            img = np.asarray(PIL.Image.open(image_filenames[order[idx]]))\n","            if channels == 1:\n","                img = img[np.newaxis, :, :] # HW => CHW\n","            else:\n","                img = img.transpose([2, 0, 1]) # HWC => CHW\n","            tfr.add_image(img)\n","\n","#----------------------------------------------------------------------------\n","\n","def create_from_hdf5(tfrecord_dir, hdf5_filename, shuffle):\n","    print('Loading HDF5 archive from \"%s\"' % hdf5_filename)\n","    import h5py # conda install h5py\n","    with h5py.File(hdf5_filename, 'r') as hdf5_file:\n","        hdf5_data = max([value for key, value in hdf5_file.items() if key.startswith('data')], key=lambda lod: lod.shape[3])\n","        with TFRecordExporter(tfrecord_dir, hdf5_data.shape[0]) as tfr:\n","            order = tfr.choose_shuffled_order() if shuffle else np.arange(hdf5_data.shape[0])\n","            for idx in range(order.size):\n","                tfr.add_image(hdf5_data[order[idx]])\n","            npy_filename = os.path.splitext(hdf5_filename)[0] + '-labels.npy'\n","            if os.path.isfile(npy_filename):\n","                tfr.add_labels(np.load(npy_filename)[order])\n","\n","#----------------------------------------------------------------------------"],"execution_count":5,"outputs":[{"output_type":"stream","text":["TensorFlow 1.x selected.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zMmRD3KL_D0j","colab_type":"code","outputId":"de648ff5-580c-49ea-9321-cbbc625bfe61","executionInfo":{"status":"ok","timestamp":1585828126466,"user_tz":-60,"elapsed":18490,"user":{"displayName":"George Cann","photoUrl":"","userId":"18306619050321749166"}},"colab":{"base_uri":"https://localhost:8080/","height":521}},"source":["def execute_cmdline(argv):\n","    print('execute_cmdline running.')\n","    prog = argv[0]\n","    parser = argparse.ArgumentParser(\n","        prog        = prog,\n","        description = 'Tool for creating multi-resolution TFRecords datasets for StyleGAN and ProGAN.',\n","        epilog      = 'Type \"%s <command> -h\" for more information.' % prog)\n","    print('parser created.')\n","    subparsers = parser.add_subparsers(dest='command')\n","    subparsers.required = True\n","    print('subparser created.')\n","    print('add_command created.')\n","    # add_command takes a command e.g. 'display' and a 'desc' i.e. description and an example\n","    def add_command(cmd, desc, example='create_from_images'):\n","        epilog = 'Example: %s %s' % (prog, example) if example is not None else None\n","        \n","        print(epilog)\n","        return subparsers.add_parser(cmd, description=desc, help=desc, epilog=epilog)\n","\n","    print('running add_command and add_argument options.')\n","\n","    p = add_command(    'display',          'Display images in dataset.',\n","                                            'display datasets/mnist')\n","    p.add_argument(     'tfrecord_dir',     help='Directory containing dataset')\n","\n","    p = add_command(    'extract',          'Extract images from dataset.',\n","                                            'extract datasets/mnist mnist-images')\n","    p.add_argument(     'tfrecord_dir',     help='Directory containing dataset')\n","    p.add_argument(     'output_dir',       help='Directory to extract the images into')\n","\n","    p = add_command(    'compare',          'Compare two datasets.',\n","                                            'compare datasets/mydataset datasets/mnist')\n","    p.add_argument(     'tfrecord_dir_a',   help='Directory containing first dataset')\n","    p.add_argument(     'tfrecord_dir_b',   help='Directory containing second dataset')\n","    p.add_argument(     '--ignore_labels',  help='Ignore labels (default: 0)', type=int, default=0)\n","\n","    p = add_command(    'create_mnist',     'Create dataset for MNIST.',\n","                                            'create_mnist datasets/mnist ~/downloads/mnist')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'mnist_dir',        help='Directory containing MNIST')\n","\n","    p = add_command(    'create_mnistrgb',  'Create dataset for MNIST-RGB.',\n","                                            'create_mnistrgb datasets/mnistrgb ~/downloads/mnist')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'mnist_dir',        help='Directory containing MNIST')\n","    p.add_argument(     '--num_images',     help='Number of composite images to create (default: 1000000)', type=int, default=1000000)\n","    p.add_argument(     '--random_seed',    help='Random seed (default: 123)', type=int, default=123)\n","\n","    p = add_command(    'create_cifar10',   'Create dataset for CIFAR-10.',\n","                                            'create_cifar10 datasets/cifar10 ~/downloads/cifar10')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'cifar10_dir',      help='Directory containing CIFAR-10')\n","\n","    p = add_command(    'create_cifar100',  'Create dataset for CIFAR-100.',\n","                                            'create_cifar100 datasets/cifar100 ~/downloads/cifar100')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'cifar100_dir',     help='Directory containing CIFAR-100')\n","\n","    p = add_command(    'create_svhn',      'Create dataset for SVHN.',\n","                                            'create_svhn datasets/svhn ~/downloads/svhn')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'svhn_dir',         help='Directory containing SVHN')\n","\n","    p = add_command(    'create_lsun',      'Create dataset for single LSUN category.',\n","                                            'create_lsun datasets/lsun-car-100k ~/downloads/lsun/car_lmdb --resolution 256 --max_images 100000')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'lmdb_dir',         help='Directory containing LMDB database')\n","    p.add_argument(     '--resolution',     help='Output resolution (default: 256)', type=int, default=256)\n","    p.add_argument(     '--max_images',     help='Maximum number of images (default: none)', type=int, default=None)\n","\n","    p = add_command(    'create_lsun_wide', 'Create LSUN dataset with non-square aspect ratio.',\n","                                            'create_lsun_wide datasets/lsun-car-512x384 ~/downloads/lsun/car_lmdb --width 512 --height 384')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'lmdb_dir',         help='Directory containing LMDB database')\n","    p.add_argument(     '--width',          help='Output width (default: 512)', type=int, default=512)\n","    p.add_argument(     '--height',         help='Output height (default: 384)', type=int, default=384)\n","    p.add_argument(     '--max_images',     help='Maximum number of images (default: none)', type=int, default=None)\n","\n","    p = add_command(    'create_celeba',    'Create dataset for CelebA.',\n","                                            'create_celeba datasets/celeba ~/downloads/celeba')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'celeba_dir',       help='Directory containing CelebA')\n","    p.add_argument(     '--cx',             help='Center X coordinate (default: 89)', type=int, default=89)\n","    p.add_argument(     '--cy',             help='Center Y coordinate (default: 121)', type=int, default=121)\n","\n","    p = add_command(    'create_from_images', 'Create dataset from a directory full of images.',\n","                                            'create_from_images datasets/mydataset myimagedir')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created',metavar='TFRECORD_DIR', default='/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord')\n","    p.add_argument(     'image_dir',        help='Directory containing the images',metavar='IMAGE_DIR', default='/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined')\n","    p.add_argument(     '--shuffle',        help='Randomize image order (default: 1)', type=int, default=1)\n","\n","    p = add_command(    'create_from_hdf5', 'Create dataset from legacy HDF5 archive.',\n","                                            'create_from_hdf5 datasets/celebahq ~/downloads/celeba-hq-1024x1024.h5')\n","    p.add_argument(     'tfrecord_dir',     help='New dataset directory to be created')\n","    p.add_argument(     'hdf5_filename',    help='HDF5 archive containing the images')\n","    p.add_argument(     '--shuffle',        help='Randomize image order (default: 1)', type=int, default=1)\n","\n","    # Pass create_from_images datasets/02_02_varepsilon_refined_tfrecord datasets/02_02_varepsilon_refined\n","    print('argv[1:]:')\n","    print(argv[1:])\n","    print('len(argv):')\n","    print(len(argv))\n","    argv = ['/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', 'create_from_images','/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord','/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined']\n","    \n","    # The arguments are set and assigned to args\n","    # create_from_images datasets/02_02_varepsilon_refined_tfrecord datasets/02_02_varepsilon_refined\n","    args = parser.parse_args(argv[1:] if len(argv) > 1 else ['-h'])\n","\n","    # args = 'create_from_images datasets/02_02_varepsilon_refined_tfrecord datasets/02_02_varepsilon_refined'\n","    print('args')\n","    print(args)\n","    func = globals()[args.command]\n","    print(func)\n","    del args.command\n","    func(**vars(args))\n","\n","#----------------------------------------------------------------------------\n","\n","#if __name__ == \"__main__\":\n","execute_cmdline(sys.argv)\n","\n","#----------------------------------------------------------------------------"],"execution_count":6,"outputs":[{"output_type":"stream","text":["execute_cmdline running.\n","parser created.\n","subparser created.\n","add_command created.\n","running add_command and add_argument options.\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py display datasets/mnist\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py extract datasets/mnist mnist-images\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py compare datasets/mydataset datasets/mnist\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_mnist datasets/mnist ~/downloads/mnist\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_mnistrgb datasets/mnistrgb ~/downloads/mnist\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_cifar10 datasets/cifar10 ~/downloads/cifar10\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_cifar100 datasets/cifar100 ~/downloads/cifar100\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_svhn datasets/svhn ~/downloads/svhn\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_lsun datasets/lsun-car-100k ~/downloads/lsun/car_lmdb --resolution 256 --max_images 100000\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_lsun_wide datasets/lsun-car-512x384 ~/downloads/lsun/car_lmdb --width 512 --height 384\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_celeba datasets/celeba ~/downloads/celeba\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_from_images datasets/mydataset myimagedir\n","Example: /usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py create_from_hdf5 datasets/celebahq ~/downloads/celeba-hq-1024x1024.h5\n","argv[1:]:\n","['-f', '/root/.local/share/jupyter/runtime/kernel-a41b332a-b6d3-45eb-8ffc-f7f42b6fdbbc.json']\n","len(argv):\n","3\n","args\n","Namespace(command='create_from_images', image_dir='/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined', shuffle=1, tfrecord_dir='/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord')\n","<function create_from_images at 0x7f1c19760d08>\n","Loading images from \"/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined\"\n","Creating dataset \"/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord\"\n","Added 124 images.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A7lFsmxerXfG","colab_type":"code","colab":{}},"source":["### Modify train.py to include the above 02_02_varepsilon_refined_tfrecord folder \n","# desc += '-02_02_varepsilon_refined';\n","# dataset = EasyDict(tfrecord_dir='02_02_varepsilon_refined_tfrecord');                 \n","# train.mirror_augment = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"20HDDGtepxt8","colab_type":"code","outputId":"81bf3347-6e8c-483d-96c2-4d838ad8c388","executionInfo":{"status":"error","timestamp":1585771139802,"user_tz":-60,"elapsed":117934,"user":{"displayName":"George Cann","photoUrl":"","userId":"18306619050321749166"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["### Training StyleGan2\n","#python run_training.py --num-gpus=8 --data-dir=~/datasets --config=config-f \\\n","#  --dataset=ffhq --mirror-augment=true\n","\n","# Default arguments\n","DATASET = '02_02_varepsilon_refined'\n","DATA_DIR = '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord'\n","DIR = '/content/drive/My Drive/StyleGan2/stylegan2-master/results/02_02_varepsilon_refined'\n","\n","# Copyright (c) 2019, NVIDIA Corporation. All rights reserved.\n","#\n","# This work is made available under the Nvidia Source Code License-NC.\n","# To view a copy of this license, visit\n","# https://nvlabs.github.io/stylegan2/license.html\n","\n","import argparse\n","import copy\n","import os\n","import sys\n","\n","import dnnlib\n","from dnnlib import EasyDict\n","\n","#from metrics.metric_defaults import metric_defaults\n","\n","#----------------------------------------------------------------------------\n","\n","metric_defaults = EasyDict(name='fid50k',    func_name='metrics.frechet_inception_distance.FID', num_images=50000, minibatch_per_gpu=8)\n","\n","#----------------------------------------------------------------------------\n","\n","_valid_configs = [\n","    # Table 1\n","    'config-a', # Baseline StyleGAN\n","    'config-b', # + Weight demodulation\n","    'config-c', # + Lazy regularization\n","    'config-d', # + Path length regularization\n","    'config-e', # + No growing, new G & D arch.\n","    'config-f', # + Large networks (default)\n","\n","    # Table 2\n","    'config-e-Gorig-Dorig',   'config-e-Gorig-Dresnet',   'config-e-Gorig-Dskip',\n","    'config-e-Gresnet-Dorig', 'config-e-Gresnet-Dresnet', 'config-e-Gresnet-Dskip',\n","    'config-e-Gskip-Dorig',   'config-e-Gskip-Dresnet',   'config-e-Gskip-Dskip',\n","]\n","\n","#----------------------------------------------------------------------------\n","\n","def run(dataset, data_dir, result_dir, config_id, num_gpus, total_kimg, gamma, mirror_augment, metrics):\n","    train     = EasyDict(run_func_name='training.training_loop.training_loop') # Options for training loop.\n","    G         = EasyDict(func_name='training.networks_stylegan2.G_main')       # Options for generator network.\n","    D         = EasyDict(func_name='training.networks_stylegan2.D_stylegan2')  # Options for discriminator network.\n","    G_opt     = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for generator optimizer.\n","    D_opt     = EasyDict(beta1=0.0, beta2=0.99, epsilon=1e-8)                  # Options for discriminator optimizer.\n","    G_loss    = EasyDict(func_name='training.loss.G_logistic_ns_pathreg')      # Options for generator loss.\n","    D_loss    = EasyDict(func_name='training.loss.D_logistic_r1')              # Options for discriminator loss.\n","    sched     = EasyDict()                                                     # Options for TrainingSchedule.\n","    grid      = EasyDict(size='8k', layout='random')                           # Options for setup_snapshot_image_grid().\n","    sc        = dnnlib.SubmitConfig()                                          # Options for dnnlib.submit_run().\n","    tf_config = {'rnd.np_random_seed': 1000}                                   # Options for tflib.init_tf().\n","\n","    train.data_dir = data_dir\n","    train.total_kimg = total_kimg\n","    train.mirror_augment = mirror_augment\n","    train.image_snapshot_ticks = train.network_snapshot_ticks = 2\n","    sched.G_lrate_base = sched.D_lrate_base = 0.002\n","    sched.minibatch_size_base = 32\n","    sched.minibatch_gpu_base = 4\n","    D_loss.gamma = 10\n","    print('Metric defaults')\n","    print(metric_defaults)\n","    metrics = metric_defaults\n","    #metrics = [metric_defaults[x] for x in metrics]\n","    #metrics = metrics\n","    desc = 'stylegan2'\n","\n","    desc += '-' + dataset\n","    dataset_args = EasyDict(tfrecord_dir=dataset)\n","\n","    assert num_gpus in [1, 2, 4, 8]\n","    sc.num_gpus = num_gpus\n","    desc += '-%dgpu' % num_gpus\n","\n","    assert config_id in _valid_configs\n","    desc += '-' + config_id\n","\n","    # Configs A-E: Shrink networks to match original StyleGAN.\n","    if config_id != 'config-f':\n","        G.fmap_base = D.fmap_base = 8 << 10\n","\n","    # Config E: Set gamma to 100 and override G & D architecture.\n","    if config_id.startswith('config-e'):\n","        D_loss.gamma = 100\n","        if 'Gorig'   in config_id: G.architecture = 'orig'\n","        if 'Gskip'   in config_id: G.architecture = 'skip' # (default)\n","        if 'Gresnet' in config_id: G.architecture = 'resnet'\n","        if 'Dorig'   in config_id: D.architecture = 'orig'\n","        if 'Dskip'   in config_id: D.architecture = 'skip'\n","        if 'Dresnet' in config_id: D.architecture = 'resnet' # (default)\n","\n","    # Configs A-D: Enable progressive growing and switch to networks that support it.\n","    if config_id in ['config-a', 'config-b', 'config-c', 'config-d']:\n","        sched.lod_initial_resolution = 8\n","        sched.G_lrate_base = sched.D_lrate_base = 0.001\n","        sched.G_lrate_dict = sched.D_lrate_dict = {128: 0.0015, 256: 0.002, 512: 0.003, 1024: 0.003}\n","        sched.minibatch_size_base = 32 # (default)\n","        sched.minibatch_size_dict = {8: 256, 16: 128, 32: 64, 64: 32}\n","        sched.minibatch_gpu_base = 4 # (default)\n","        sched.minibatch_gpu_dict = {8: 32, 16: 16, 32: 8, 64: 4}\n","        G.synthesis_func = 'G_synthesis_stylegan_revised'\n","        D.func_name = 'training.networks_stylegan2.D_stylegan'\n","\n","    # Configs A-C: Disable path length regularization.\n","    if config_id in ['config-a', 'config-b', 'config-c']:\n","        G_loss = EasyDict(func_name='training.loss.G_logistic_ns')\n","\n","    # Configs A-B: Disable lazy regularization.\n","    if config_id in ['config-a', 'config-b']:\n","        train.lazy_regularization = False\n","\n","    # Config A: Switch to original StyleGAN networks.\n","    if config_id == 'config-a':\n","        G = EasyDict(func_name='training.networks_stylegan.G_style')\n","        D = EasyDict(func_name='training.networks_stylegan.D_basic')\n","\n","    if gamma is not None:\n","        D_loss.gamma = gamma\n","\n","    sc.submit_target = dnnlib.SubmitTarget.LOCAL\n","    sc.local.do_not_copy_source_files = True\n","    kwargs = EasyDict(train)\n","    kwargs.update(G_args=G, D_args=D, G_opt_args=G_opt, D_opt_args=D_opt, G_loss_args=G_loss, D_loss_args=D_loss)\n","    kwargs.update(dataset_args=dataset_args, sched_args=sched, grid_args=grid, metric_arg_list=metrics, tf_config=tf_config)\n","    kwargs.submit_config = copy.deepcopy(sc)\n","    kwargs.submit_config.run_dir_root = result_dir\n","    kwargs.submit_config.run_desc = desc\n","    dnnlib.submit_run(**kwargs)\n","\n","#----------------------------------------------------------------------------\n","\n","def _str_to_bool(v):\n","    if isinstance(v, bool):\n","        return v\n","    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n","        return True\n","    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n","        return False\n","    else:\n","        raise argparse.ArgumentTypeError('Boolean value expected.')\n","\n","def _parse_comma_sep(s):\n","    if s is None or s.lower() == 'none' or s == '':\n","        return []\n","    return s.split(',')\n","\n","#----------------------------------------------------------------------------\n","\n","_examples = '''examples:\n","  # Train StyleGAN2 using the FFHQ dataset\n","  python %(prog)s --num-gpus=8 --data-dir=~/datasets --config=config-f --dataset=ffhq --mirror-augment=true\n","valid configs:\n","  ''' + ', '.join(_valid_configs) + '''\n","valid metrics:\n","  ''' + ', '.join(sorted([x for x in metric_defaults.keys()])) + '''\n","'''\n","\n","def main():\n","    parser = argparse.ArgumentParser(\n","        description='Train StyleGAN2.',\n","        epilog=_examples,\n","        formatter_class=argparse.RawDescriptionHelpFormatter\n","    )\n","    parser.add_argument('--result-dir', help='Root directory for run results (default: %(default)s)', default='results', metavar='DIR')\n","    parser.add_argument('--data-dir', help='Dataset root directory', required=True,metavar='DATA_DIR')\n","    parser.add_argument('--dataset', help='Training dataset', required=True,metavar='DATASET')\n","    parser.add_argument('--config', help='Training config (default: %(default)s)', default='config-f', required=True, dest='config_id', metavar='CONFIG')\n","    parser.add_argument('--num-gpus', help='Number of GPUs (default: %(default)s)', default=1, type=int, metavar='N')\n","    parser.add_argument('--total-kimg', help='Training length in thousands of images (default: %(default)s)', metavar='KIMG', default=25000, type=int)\n","    parser.add_argument('--gamma', help='R1 regularization weight (default is config dependent)', default=None, type=float)\n","    parser.add_argument('--mirror-augment', help='Mirror augment (default: %(default)s)', default=False, metavar='BOOL', type=_str_to_bool)\n","    parser.add_argument('--metrics', help='Comma-separated list of metrics or \"none\" (default: %(default)s)', default=None, type=_parse_comma_sep)\n","\n","    DATASET = '02_02_varepsilon_refined'\n","    DATA_DIR = '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets'\n","    DIR = '/content/drive/My Drive/StyleGan2/stylegan2-master/results/02_02_varepsilon_refined'\n","\n","    argv = ['/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py', DATA_DIR,DATASET,DIR]\n","    \n","    args = argv[1:] if len(argv) > 1 else ['-h']\n","    # args = parser.parse_args()\n","    print('args')\n","    print(args)\n","\n","    #if not os.path.exists(args.data_dir):\n","    #    print ('Error: dataset root directory does not exist.')\n","    #    sys.exit(1)\n","\n","    #if args.config_id not in _valid_configs:\n","    #    print ('Error: --config value must be one of: ', ', '.join(_valid_configs))\n","    #    sys.exit(1)\n","\n","    #for metric in args.metrics:\n","    #    if metric not in metric_defaults:\n","    #        print ('Error: unknown metric \\'%s\\'' % metric)\n","    #        sys.exit(1)\n","    \n","    # Python raises a KeyError whenever a dict() object is requested (using the format a = adict[key]) and the key is not in the dictionary.\n","\n","    # run(**vars(args))\n","    run(dataset='02_02_varepsilon_refined', data_dir='/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/', result_dir='/content/drive/My Drive/StyleGan2/stylegan2-master/results/02_02_varepsilon_refined', config_id='config-f', num_gpus=1, total_kimg=10000, gamma=None, mirror_augment=False, metrics=None)\n","\n","#----------------------------------------------------------------------------\n","\n","#if __name__ == \"__main__\":\n","main()\n","\n","#----------------------------------------------------------------------------\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["args\n","['/content/drive/My Drive/StyleGan2/stylegan2-master/datasets', '02_02_varepsilon_refined', '/content/drive/My Drive/StyleGan2/stylegan2-master/results/02_02_varepsilon_refined']\n","Metric defaults\n","{'name': 'fid50k', 'func_name': 'metrics.frechet_inception_distance.FID', 'num_images': 50000, 'minibatch_per_gpu': 8}\n","Local submit - run_dir: /content/drive/My Drive/StyleGan2/stylegan2-master/results/02_02_varepsilon_refined/00021-stylegan2-02_02_varepsilon_refined-1gpu-config-f\n","dnnlib: Running training.training_loop.training_loop() on localhost...\n","Streaming data using training.dataset.TFRecordDataset...\n","/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined\n","['/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r02.tfrecords', '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r03.tfrecords', '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r04.tfrecords', '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r05.tfrecords', '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r06.tfrecords', '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r07.tfrecords', '/content/drive/My Drive/StyleGan2/stylegan2-master/datasets/02_02_varepsilon_refined_tfrecord/02_02_varepsilon_refined_tfrecord-r08.tfrecords']\n","Dataset shape = [1, 256, 256]\n","Dynamic range = [0, 255]\n","Label size    = 0\n","Constructing networks...\n","Setting up TensorFlow plugin \"fused_bias_act.cu\": Preprocessing... Loading... Done.\n","Setting up TensorFlow plugin \"upfirdn_2d.cu\": Preprocessing... Loading... Done.\n","\n","G                             Params    OutputShape         WeightShape     \n","---                           ---       ---                 ---             \n","latents_in                    -         (?, 512)            -               \n","labels_in                     -         (?, 0)              -               \n","lod                           -         ()                  -               \n","dlatent_avg                   -         (512,)              -               \n","G_mapping/latents_in          -         (?, 512)            -               \n","G_mapping/labels_in           -         (?, 0)              -               \n","G_mapping/Normalize           -         (?, 512)            -               \n","G_mapping/Dense0              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense1              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense2              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense3              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense4              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense5              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense6              262656    (?, 512)            (512, 512)      \n","G_mapping/Dense7              262656    (?, 512)            (512, 512)      \n","G_mapping/Broadcast           -         (?, 14, 512)        -               \n","G_mapping/dlatents_out        -         (?, 14, 512)        -               \n","Truncation/Lerp               -         (?, 14, 512)        -               \n","G_synthesis/dlatents_in       -         (?, 14, 512)        -               \n","G_synthesis/4x4/Const         8192      (?, 512, 4, 4)      (1, 512, 4, 4)  \n","G_synthesis/4x4/Conv          2622465   (?, 512, 4, 4)      (3, 3, 512, 512)\n","G_synthesis/4x4/ToRGB         263169    (?, 1, 4, 4)        (1, 1, 512, 1)  \n","G_synthesis/8x8/Conv0_up      2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Conv1         2622465   (?, 512, 8, 8)      (3, 3, 512, 512)\n","G_synthesis/8x8/Upsample      -         (?, 1, 8, 8)        -               \n","G_synthesis/8x8/ToRGB         263169    (?, 1, 8, 8)        (1, 1, 512, 1)  \n","G_synthesis/16x16/Conv0_up    2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Conv1       2622465   (?, 512, 16, 16)    (3, 3, 512, 512)\n","G_synthesis/16x16/Upsample    -         (?, 1, 16, 16)      -               \n","G_synthesis/16x16/ToRGB       263169    (?, 1, 16, 16)      (1, 1, 512, 1)  \n","G_synthesis/32x32/Conv0_up    2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Conv1       2622465   (?, 512, 32, 32)    (3, 3, 512, 512)\n","G_synthesis/32x32/Upsample    -         (?, 1, 32, 32)      -               \n","G_synthesis/32x32/ToRGB       263169    (?, 1, 32, 32)      (1, 1, 512, 1)  \n","G_synthesis/64x64/Conv0_up    2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Conv1       2622465   (?, 512, 64, 64)    (3, 3, 512, 512)\n","G_synthesis/64x64/Upsample    -         (?, 1, 64, 64)      -               \n","G_synthesis/64x64/ToRGB       263169    (?, 1, 64, 64)      (1, 1, 512, 1)  \n","G_synthesis/128x128/Conv0_up  1442561   (?, 256, 128, 128)  (3, 3, 512, 256)\n","G_synthesis/128x128/Conv1     721409    (?, 256, 128, 128)  (3, 3, 256, 256)\n","G_synthesis/128x128/Upsample  -         (?, 1, 128, 128)    -               \n","G_synthesis/128x128/ToRGB     131585    (?, 1, 128, 128)    (1, 1, 256, 1)  \n","G_synthesis/256x256/Conv0_up  426369    (?, 128, 256, 256)  (3, 3, 256, 128)\n","G_synthesis/256x256/Conv1     213249    (?, 128, 256, 256)  (3, 3, 128, 128)\n","G_synthesis/256x256/Upsample  -         (?, 1, 256, 256)    -               \n","G_synthesis/256x256/ToRGB     65793     (?, 1, 256, 256)    (1, 1, 128, 1)  \n","G_synthesis/images_out        -         (?, 1, 256, 256)    -               \n","G_synthesis/noise0            -         (1, 1, 4, 4)        -               \n","G_synthesis/noise1            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise2            -         (1, 1, 8, 8)        -               \n","G_synthesis/noise3            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise4            -         (1, 1, 16, 16)      -               \n","G_synthesis/noise5            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise6            -         (1, 1, 32, 32)      -               \n","G_synthesis/noise7            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise8            -         (1, 1, 64, 64)      -               \n","G_synthesis/noise9            -         (1, 1, 128, 128)    -               \n","G_synthesis/noise10           -         (1, 1, 128, 128)    -               \n","G_synthesis/noise11           -         (1, 1, 256, 256)    -               \n","G_synthesis/noise12           -         (1, 1, 256, 256)    -               \n","images_out                    -         (?, 1, 256, 256)    -               \n","---                           ---       ---                 ---             \n","Total                         30028436                                      \n","\n","\n","D                    Params    OutputShape         WeightShape     \n","---                  ---       ---                 ---             \n","images_in            -         (?, 1, 256, 256)    -               \n","labels_in            -         (?, 0)              -               \n","256x256/FromRGB      256       (?, 128, 256, 256)  (1, 1, 1, 128)  \n","256x256/Conv0        147584    (?, 128, 256, 256)  (3, 3, 128, 128)\n","256x256/Conv1_down   295168    (?, 256, 128, 128)  (3, 3, 128, 256)\n","256x256/Skip         32768     (?, 256, 128, 128)  (1, 1, 128, 256)\n","128x128/Conv0        590080    (?, 256, 128, 128)  (3, 3, 256, 256)\n","128x128/Conv1_down   1180160   (?, 512, 64, 64)    (3, 3, 256, 512)\n","128x128/Skip         131072    (?, 512, 64, 64)    (1, 1, 256, 512)\n","64x64/Conv0          2359808   (?, 512, 64, 64)    (3, 3, 512, 512)\n","64x64/Conv1_down     2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n","64x64/Skip           262144    (?, 512, 32, 32)    (1, 1, 512, 512)\n","32x32/Conv0          2359808   (?, 512, 32, 32)    (3, 3, 512, 512)\n","32x32/Conv1_down     2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n","32x32/Skip           262144    (?, 512, 16, 16)    (1, 1, 512, 512)\n","16x16/Conv0          2359808   (?, 512, 16, 16)    (3, 3, 512, 512)\n","16x16/Conv1_down     2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n","16x16/Skip           262144    (?, 512, 8, 8)      (1, 1, 512, 512)\n","8x8/Conv0            2359808   (?, 512, 8, 8)      (3, 3, 512, 512)\n","8x8/Conv1_down       2359808   (?, 512, 4, 4)      (3, 3, 512, 512)\n","8x8/Skip             262144    (?, 512, 4, 4)      (1, 1, 512, 512)\n","4x4/MinibatchStddev  -         (?, 513, 4, 4)      -               \n","4x4/Conv             2364416   (?, 512, 4, 4)      (3, 3, 513, 512)\n","4x4/Dense0           4194816   (?, 512)            (8192, 512)     \n","Output               513       (?, 1)              (512, 1)        \n","scores_out           -         (?, 1)              -               \n","---                  ---       ---                 ---             \n","Total                28863873                                      \n","\n","Building TensorFlow graph...\n","Initializing logs...\n","Metric keyword arguement list:\n","{'name': 'fid50k', 'func_name': 'metrics.frechet_inception_distance.FID', 'num_images': 50000, 'minibatch_per_gpu': 8}\n","Training for 10000 kimg...\n","\n","tick 0     kimg 0.1      lod 0.00  minibatch 32   time 42s          sec/tick 41.6    sec/kimg 325.29  maintenance 0.0    gpumem 6.1\n","tick 1     kimg 8.2      lod 0.00  minibatch 32   time 27m 58s      sec/tick 1608.2  sec/kimg 199.43  maintenance 28.2   gpumem 6.1\n","tick 2     kimg 16.3     lod 0.00  minibatch 32   time 54m 46s      sec/tick 1608.0  sec/kimg 199.41  maintenance 0.0    gpumem 6.1\n","tick 3     kimg 24.3     lod 0.00  minibatch 32   time 1h 21m 49s   sec/tick 1608.9  sec/kimg 199.52  maintenance 14.2   gpumem 6.1\n","tick 4     kimg 32.4     lod 0.00  minibatch 32   time 1h 48m 38s   sec/tick 1608.7  sec/kimg 199.50  maintenance 0.0    gpumem 6.1\n","tick 5     kimg 40.4     lod 0.00  minibatch 32   time 2h 15m 39s   sec/tick 1605.8  sec/kimg 199.13  maintenance 14.9   gpumem 6.1\n","tick 6     kimg 48.5     lod 0.00  minibatch 32   time 2h 42m 29s   sec/tick 1610.5  sec/kimg 199.71  maintenance 0.0    gpumem 6.1\n","tick 7     kimg 56.6     lod 0.00  minibatch 32   time 3h 09m 38s   sec/tick 1612.1  sec/kimg 199.91  maintenance 16.8   gpumem 6.1\n","tick 8     kimg 64.6     lod 0.00  minibatch 32   time 3h 36m 29s   sec/tick 1611.4  sec/kimg 199.83  maintenance 0.0    gpumem 6.1\n","tick 9     kimg 72.7     lod 0.00  minibatch 32   time 4h 03m 37s   sec/tick 1609.8  sec/kimg 199.63  maintenance 17.8   gpumem 6.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9uZEDtvDL9B7","colab_type":"code","colab":{}},"source":["cd /content/drive/My Drive/StyleGan2/stylegan2-master/datasets\n"],"execution_count":0,"outputs":[]}]}